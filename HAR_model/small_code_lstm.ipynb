{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNP1eBiBm5m4BVPlScMRelj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boradj/Time-series-ML/blob/main/HAR_model/small_code_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "#This will prompt for authorization # to take permission from user to use google drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L0tbM-H2OK0",
        "outputId": "6eb30526-b346-4c55-cda2-1b63df19c032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM95ojck0k4s",
        "outputId": "1d975668-5a59-476a-d9a2-6125c6b0b58a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            ">#1: 88.700\n",
            "[88.70037198066711]\n",
            "Accuracy: 88.700% (+/-0.000)\n"
          ]
        }
      ],
      "source": [
        "from IPython.lib.display import YouTubeVideo\n",
        "from re import X\n",
        "\n",
        "from keras.engine.training import Model\n",
        "\n",
        "# lstm model\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from matplotlib import pyplot\n",
        "# load a single file as a numpy array\n",
        "\n",
        "\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        " \n",
        "# load a list of files and return as a 3d numpy array\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded\n",
        " \n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset_group(group, prefix=''):\n",
        "\tfilepath = prefix + group + '/Inertial Signals/'\n",
        "\t# load all 9 files as a single array\n",
        "\tfilenames = list()\n",
        "\t# total acceleration\n",
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "\t# body acceleration\n",
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "\t# body gyroscope\n",
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "\t# load input data\n",
        "\tX = load_group(filenames, filepath)\n",
        "\t# load class output\n",
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "\treturn X, y\n",
        " \n",
        "# load the dataset, returns train and test X and y elements\n",
        "def load_dataset(prefix=''):\n",
        "\t# load all train\n",
        "\ttrainX, trainy = load_dataset_group('train', prefix + '/content/drive/My Drive/UCI HAR Dataset/')\n",
        "\tprint(trainX.shape, trainy.shape)\n",
        "\t# load all test\n",
        "\ttestX, testy = load_dataset_group('test', prefix + '/content/drive/My Drive/UCI HAR Dataset/')\n",
        "\tprint(testX.shape, testy.shape)\n",
        "\t# zero-offset class values\n",
        "\ttrainy = trainy - 1\n",
        "\ttesty = testy - 1\n",
        "\t# one hot encode y\n",
        "\ttrainy = to_categorical(trainy)\n",
        "\ttesty = to_categorical(testy)\n",
        "\tprint(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "\treturn trainX, trainy, testX, testy\n",
        " \n",
        "# fit and evaluate a model\n",
        "def evaluate_model(trainX, trainy, testX, testy):\n",
        "\tverbose, epochs, batch_size = 7352, 30, 64\n",
        "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\tglobal P, X, Y\n",
        "\tY = testy\n",
        "\tX = testX\n",
        "\tP = model\n",
        "\t# fit network\n",
        "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\t# evaluate model\n",
        "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "\treturn accuracy\n",
        " \n",
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "\tprint(scores)\n",
        "\tm, s = mean(scores), std(scores)\n",
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        " \n",
        "# run an experiment\n",
        "def run_experiment(repeats=1):\n",
        "\t# load data\n",
        "\ttrainX, trainy, testX, testy = load_dataset()\n",
        "\t# repeat experiment\n",
        "\tscores = list()\n",
        "\tfor r in range(repeats):\n",
        "\t\tscore = evaluate_model(trainX, trainy, testX, testy)\n",
        "\t\tscore = score * 100\n",
        "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
        "\t\tscores.append(score)\n",
        "\t# summarize results\n",
        "\tsummarize_results(scores)\n",
        " \t\n",
        " \n",
        "# run the experiment\n",
        "run_experiment()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(P)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TJU8LF3EvUa",
        "outputId": "39941a72-66c8-410a-f5a9-6aa7a0f6ae73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.engine.sequential.Sequential object at 0x7f0f521c3950>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from  sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "model = P\n",
        "# save\n",
        "with open('model.pkl','wb') as f:\n",
        "    pickle.dump(model,f)\n",
        "\n",
        "# load\n",
        "with open('model.pkl', 'rb') as f:\n",
        "    clf2 = pickle.load(f)\n",
        "testX = X\n",
        "predict_x =clf2.predict(testX) \n",
        "y_pred=np.argmax(predict_x,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o58j0ssvfo5c",
        "outputId": "da6a82a3-9eba-47b6-85a3-ebc3765ee2a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://d35b8fc8-6db0-4d79-a811-646be177e9d3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://d35b8fc8-6db0-4d79-a811-646be177e9d3/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0f4cf5a790> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testy = Y\n",
        "_, accuracy = model.evaluate(testX, testy, batch_size=64, verbose=0)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6poiDjiH2bm",
        "outputId": "62810b99-9972-4555-85cf-3708942c906d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8870037198066711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "mat = confusion_matrix(testy, y_pred)\n",
        "plot_confusion_matrix(conf_mat=mat, show_normed=True, figsize=(7,7))\n",
        "#plot_confusion_matrix(mat, y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "roXV38WDLwEC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "ccf86179-0f50-4c6c-8e70-8a040b76d155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2dd5915484af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_normed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'testy' is not defined"
          ]
        }
      ]
    }
  ]
}